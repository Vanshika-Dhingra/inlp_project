{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fastBPE sacremoses subword_nmt ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:11:12.535642Z","iopub.execute_input":"2025-04-07T18:11:12.535896Z","iopub.status.idle":"2025-04-07T18:11:27.049206Z","shell.execute_reply.started":"2025-04-07T18:11:12.535876Z","shell.execute_reply":"2025-04-07T18:11:27.047915Z"}},"outputs":[{"name":"stdout","text":"Collecting fastBPE\n  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nCollecting subword_nmt\n  Downloading subword_nmt-0.3.8-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.67.1)\nCollecting mock (from subword_nmt)\n  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\nDownloading mock-5.2.0-py3-none-any.whl (31 kB)\nBuilding wheels for collected packages: fastBPE\n  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp310-cp310-linux_x86_64.whl size=806541 sha256=6057a6fb53634e80d18e64e2fa9b7b5990213063e46ed32789b001eeb3db2e5e\n  Stored in directory: /root/.cache/pip/wheels/13/5d/b9/4b8897941ebc9e8c6cc3f3ffd3ea5115731754269205098754\nSuccessfully built fastBPE\nInstalling collected packages: fastBPE, sacremoses, mock, subword_nmt\nSuccessfully installed fastBPE-0.1.0 mock-5.2.0 sacremoses-0.1.1 subword_nmt-0.3.8\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install scikit-learn \n!pip install scipy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:11:27.050211Z","iopub.execute_input":"2025-04-07T18:11:27.050575Z","iopub.status.idle":"2025-04-07T18:11:33.591213Z","shell.execute_reply.started":"2025-04-07T18:11:27.050541Z","shell.execute_reply":"2025-04-07T18:11:33.590248Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\npip install hydra-core bitarray sacrebleu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:11:33.592264Z","iopub.execute_input":"2025-04-07T18:11:33.592604Z","iopub.status.idle":"2025-04-07T18:11:38.319768Z","shell.execute_reply.started":"2025-04-07T18:11:33.592580Z","shell.execute_reply":"2025-04-07T18:11:38.318853Z"}},"outputs":[{"name":"stdout","text":"Collecting hydra-core\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting bitarray\n  Downloading bitarray-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core) (2.3.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (24.2)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: bitarray, portalocker, hydra-core, sacrebleu\nSuccessfully installed bitarray-3.3.1 hydra-core-1.3.2 portalocker-3.1.1 sacrebleu-2.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\n\n# List available models\ntorch.hub.list('pytorch/fairseq')  # [..., 'transformer.wmt16.en-de', ... ]\n\n# Load a transformer trained on WMT'16 En-De\n# Note: WMT'19 models use fastBPE instead of subword_nmt, see instructions below\nen2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr',\n                       tokenizer='moses', bpe='subword_nmt')\nen2de.eval()  # disable dropout\n\n# The underlying model is available under the *models* attribute\n# assert isinstance(en2de.models[0], fairseq.models.transformer.TransformerModel)\n\n# Move model to GPU for faster translation\nen2de.cuda()\n\n# Translate a sentence\nen2de.translate('Hello world!')\n# 'Hallo Welt!'\n\n# Batched translation\nen2de.translate(['Hello world!', 'The cat sat on the mat.'])\n# ['Hallo Welt!', 'Die Katze saß auf der Matte.']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:11:38.323405Z","iopub.execute_input":"2025-04-07T18:11:38.323632Z","iopub.status.idle":"2025-04-07T18:27:15.106629Z","shell.execute_reply.started":"2025-04-07T18:11:38.323609Z","shell.execute_reply":"2025-04-07T18:27:15.105748Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/fairseq/zipball/main\" to /root/.cache/torch/hub/main.zip\n/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/tasks/multires_hubert_pretraining.py:154: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  dictionaries = [ (Dictionary.load(f\"{label_dir}/dict.{label}.txt\") if label is not \"\" else None ) for label in self.cfg.labels]\n/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py:261: UserWarning: Unknown distribution option: 'test_suite'\n  warnings.warn(msg)\n/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:416: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:426: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","output_type":"stream"},{"name":"stdout","text":"[1/1] Cythonizing fairseq/data/data_utils_fast.pyx\n","output_type":"stream"},{"name":"stderr","text":"Emitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","output_type":"stream"},{"name":"stdout","text":"[1/1] Cythonizing fairseq/data/token_block_utils_fast.pyx\n","output_type":"stream"},{"name":"stderr","text":"Emitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nEmitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_main/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nUsing cache found in /root/.cache/torch/hub/pytorch_fairseq_main\n100%|██████████| 2316140317/2316140317 [02:59<00:00, 12927202.07B/s]\n/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f, map_location=torch.device(\"cpu\"))\n/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n  deprecation_warning(message=message)\n/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:45: UserWarning: \nThe version_base parameter is not specified.\nPlease specify a compatability version level, or None.\nWill assume defaults for version 1.1\n  self.delegate = real_initialize(\n/usr/local/lib/python3.10/dist-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n  deprecation_warning(message=message)\n/usr/local/lib/python3.10/dist-packages/hydra/core/default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\nSee https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n  deprecation_warning(\n/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:450: UserWarning: \n'config' is validated against ConfigStore schema with the same name.\nThis behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\nSee https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n  state = load_checkpoint_to_cpu(filename, arg_overrides)\n/usr/local/lib/python3.10/dist-packages/hydra/compose.py:56: UserWarning: \nThe strict flag in the compose API is deprecated.\nSee https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n\n  deprecation_warning(\n/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n  deprecation_warning(message=message)\n/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:45: UserWarning: \nThe version_base parameter is not specified.\nPlease specify a compatability version level, or None.\nWill assume defaults for version 1.1\n  self.delegate = real_initialize(\n/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/fairseq_model.py:272: UserWarning: \n'config' is validated against ConfigStore schema with the same name.\nThis behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\nSee https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n  x = hub_utils.from_pretrained(\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['Bonjour à tous !', 'Le chat était assis sur le tapis.']"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"param_dict = {}\nfor name, param in en2de.named_parameters():\n    if 'weight' in name and 'layernorm' not in name.lower():\n        param_dict[name] = param.detach().cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:15.108289Z","iopub.execute_input":"2025-04-07T18:27:15.108957Z","iopub.status.idle":"2025-04-07T18:27:16.015198Z","shell.execute_reply.started":"2025-04-07T18:27:15.108929Z","shell.execute_reply":"2025-04-07T18:27:16.014419Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:16.016332Z","iopub.execute_input":"2025-04-07T18:27:16.016603Z","iopub.status.idle":"2025-04-07T18:27:16.020482Z","shell.execute_reply.started":"2025-04-07T18:27:16.016582Z","shell.execute_reply":"2025-04-07T18:27:16.019432Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def class_uniform_pruning(param_dict, prune_ratio):\n    mask_dict = {}\n    for name, weights in param_dict.items():\n        threshold = np.percentile(np.abs(weights), prune_ratio * 100)\n        mask = np.abs(weights) > threshold\n        mask_dict[name] = mask\n    return mask_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:16.021445Z","iopub.execute_input":"2025-04-07T18:27:16.021724Z","iopub.status.idle":"2025-04-07T18:27:16.037050Z","shell.execute_reply.started":"2025-04-07T18:27:16.021701Z","shell.execute_reply":"2025-04-07T18:27:16.036176Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def class_blind_pruning(param_dict, prune_ratio):\n    all_weights = np.concatenate([w.flatten() for w in param_dict.values()])\n    threshold = np.percentile(np.abs(all_weights), prune_ratio * 100)\n\n    mask_dict = {}\n    for name, weights in param_dict.items():\n        mask = np.abs(weights) > threshold\n        mask_dict[name] = mask\n    return mask_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:16.039742Z","iopub.execute_input":"2025-04-07T18:27:16.039969Z","iopub.status.idle":"2025-04-07T18:27:16.056958Z","shell.execute_reply.started":"2025-04-07T18:27:16.039949Z","shell.execute_reply":"2025-04-07T18:27:16.055988Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def class_distribution_pruning(param_dict, prune_ratio):\n    # Search for lambda such that total pruned weights ≈ x%\n    def compute_total_pruned(lambda_val):\n        total = 0\n        pruned = 0\n        for weights in param_dict.values():\n            sigma = np.std(weights)\n            threshold = lambda_val * sigma\n            pruned += np.sum(np.abs(weights) < threshold)\n            total += weights.size\n        return pruned / total\n\n    # Binary search for lambda\n    low, high = 0.0, 10.0\n    for _ in range(20):\n        mid = (low + high) / 2\n        ratio = compute_total_pruned(mid)\n        if ratio < prune_ratio:\n            low = mid\n        else:\n            high = mid\n    lambda_opt = (low + high) / 2\n\n    # Generate mask using the found lambda\n    mask_dict = {}\n    for name, weights in param_dict.items():\n        sigma = np.std(weights)\n        threshold = lambda_opt * sigma\n        mask = np.abs(weights) > threshold\n        mask_dict[name] = mask\n    return mask_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:16.058645Z","iopub.execute_input":"2025-04-07T18:27:16.058919Z","iopub.status.idle":"2025-04-07T18:27:16.073630Z","shell.execute_reply.started":"2025-04-07T18:27:16.058897Z","shell.execute_reply":"2025-04-07T18:27:16.072751Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def apply_masks_to_model(model, mask_dict):\n    for name, param in model.named_parameters():\n        if name in mask_dict:\n            mask = torch.tensor(mask_dict[name], dtype=param.dtype, device=param.device)\n            with torch.no_grad():\n                param.mul_(mask)  # In-place pruning\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:16.074579Z","iopub.execute_input":"2025-04-07T18:27:16.074937Z","iopub.status.idle":"2025-04-07T18:27:16.094246Z","shell.execute_reply.started":"2025-04-07T18:27:16.074903Z","shell.execute_reply":"2025-04-07T18:27:16.093376Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# mask_dict = class_blind_pruning(param_dict,0.1)\n# pruned_model = apply_masks_to_model(en2de, mask_dict)\n# torch.save(pruned_model.state_dict(), 'pruned_model_weights.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:16.095254Z","iopub.execute_input":"2025-04-07T18:27:16.095585Z","iopub.status.idle":"2025-04-07T18:27:22.576969Z","shell.execute_reply.started":"2025-04-07T18:27:16.095551Z","shell.execute_reply":"2025-04-07T18:27:22.576109Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# mask_dict_1 = class_uniform_pruning(param_dict,0.1)\n# pruned_model_blind = apply_masks_to_model(en2de, mask_dict_1)\n# torch.save(pruned_model_blind.state_dict(), 'pruned_model_blind_weights.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:22.577925Z","iopub.execute_input":"2025-04-07T18:27:22.578254Z","iopub.status.idle":"2025-04-07T18:27:28.494484Z","shell.execute_reply.started":"2025-04-07T18:27:22.578223Z","shell.execute_reply":"2025-04-07T18:27:28.493420Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# mask_dict_2 = class_uniform_pruning(param_dict,0.1)\n# pruned_model_distribution = apply_masks_to_model(en2de, mask_dict_2)\n# torch.save(pruned_model_distribution.state_dict(), 'pruned_model_distribution_weights.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:28.495603Z","iopub.execute_input":"2025-04-07T18:27:28.495933Z","iopub.status.idle":"2025-04-07T18:27:34.294093Z","shell.execute_reply.started":"2025-04-07T18:27:28.495911Z","shell.execute_reply":"2025-04-07T18:27:34.293361Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:34.294890Z","iopub.execute_input":"2025-04-07T18:27:34.295142Z","iopub.status.idle":"2025-04-07T18:27:38.254208Z","shell.execute_reply.started":"2025-04-07T18:27:34.295119Z","shell.execute_reply":"2025-04-07T18:27:38.252856Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load WMT14 en-fr test set\nwmt14 = load_dataset(\"wmt14\", \"fr-en\", split=\"test\")\n\n# Extract English sources and French references\ntest_sentences_en = [example[\"translation\"][\"en\"] for example in wmt14]\ntest_references_fr = [[example[\"translation\"][\"fr\"]] for example in wmt14]\n\nprint(f\"Loaded {len(test_sentences_en)} test examples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:27:38.255540Z","iopub.execute_input":"2025-04-07T18:27:38.255895Z","iopub.status.idle":"2025-04-07T18:30:06.810519Z","shell.execute_reply.started":"2025-04-07T18:27:38.255866Z","shell.execute_reply":"2025-04-07T18:30:06.809471Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef83b43ac7764b29b4cd614e22159bd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9a12be0d51942799ab3443feb5211b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/30 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60782633028432aaaf6a0bbc68d700c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00030.parquet:   0%|          | 0.00/252M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0fddf34b30d470abd974edb22dd84ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00030.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f077440edc74f60ac911eb4c6bb3014"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00030.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1beb860aebb4c72a64fa08699964276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00030.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f50571e2b3c4f6a9792796434f79091"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00030.parquet:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4d84f8a19945ff94af0fc1c82df4f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00030.parquet:   0%|          | 0.00/238M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b08226269119451994fa33ede5d3b37a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00030.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8a130c1c497479fbaa6efbb6b975aa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00030.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931df03813924885b76043bbd4fe8a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00030.parquet:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df984bdea6a4ac8b3bf50975562c06e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00030.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbfdc3eefe3415b88a6d45a7e7de330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00030.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed6c9ed34cc469ab8a4a61b8de03edb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00030.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"806acae6f60047f5a589a527cc90ac98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00030.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d38a1206ff249d1b5ee4ec37e445f47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00030.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed1c7b49d4a94e22ae4c474453de9f89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00030.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c780e719a4ca49c3a94e320bad7d336b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00030.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1024ee80b6034a9d978d04ce3dc273c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00030.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b13007f39b44ef3b9d77bff81c7ebaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00030.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e3e5644473d4f628e0748572900f453"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00030.parquet:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b411a434354a9995335544c7b309e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00030.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08c39ffc2304be1aaf87d4625289c6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00030.parquet:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"511e0f6e283249319078222aef64ac2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00030.parquet:   0%|          | 0.00/264M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7711240ea18a46e289ff0fe6732b1496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00030.parquet:   0%|          | 0.00/267M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4a1260e14c465e905be1be63c824e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00030.parquet:   0%|          | 0.00/270M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f218c29d055499598b564186c6181d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00030.parquet:   0%|          | 0.00/274M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3622e24460534ce7a6a7b0839d04ebae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00030.parquet:   0%|          | 0.00/278M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c5a56e293014daab72910cfac4bf202"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00030.parquet:   0%|          | 0.00/365M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e627ff3aa11d4d989026c9d157f0560c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00030.parquet:   0%|          | 0.00/322M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba0ecb6756794cb6b928a7505c409d26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00030.parquet:   0%|          | 0.00/370M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83c74437f4124a90b6ee0f18aa6a222b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00030.parquet:   0%|          | 0.00/311M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6438be48d91a4f7fb1aee83cb5ab7625"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/475k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"034623e091ba42299439392505799b6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/536k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e5d3e56b51048f680ba2d0d22084d6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/40836715 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c3645e72ec46a999cacab67d2c210a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1280141602542c8918b626d103c423f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeda802efc994a60bfda6e025a53737b"}},"metadata":{}},{"name":"stdout","text":"Loaded 3003 test examples\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sacrebleu import corpus_bleu\nimport torch\n\ndef evaluate_bleu(model, source_sentences, reference_sentences, batch_size=32):\n    \"\"\"\n    Evaluate BLEU score with batching for large datasets\n    \n    Args:\n        model: The translation model\n        source_sentences: List of source language sentences\n        reference_sentences: List of lists of reference translations\n        batch_size: Number of sentences to process at once\n    \n    Returns:\n        BLEU score\n    \"\"\"\n    translations = []\n    \n    # Process in batches to avoid memory issues\n    for i in range(0, len(source_sentences), batch_size):\n        batch = source_sentences[i:i+batch_size]\n        batch_translations = model.translate(batch)\n        translations.extend(batch_translations)\n    \n    # Calculate BLEU score\n    bleu_score = corpus_bleu(translations, reference_sentences)\n    \n    return bleu_score.score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:30:06.811650Z","iopub.execute_input":"2025-04-07T18:30:06.812353Z","iopub.status.idle":"2025-04-07T18:30:06.817705Z","shell.execute_reply.started":"2025-04-07T18:30:06.812327Z","shell.execute_reply":"2025-04-07T18:30:06.816638Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# # Evaluate original model\n# print(\"Evaluating original model...\")\n# original_bleu = evaluate_bleu(en2de, test_sentences_en, test_references_de)\n# print(f\"Original model BLEU score: {original_bleu:.2f}\")\n\n# # Evaluate class-blind pruned model\n# print(\"\\nEvaluating class-blind pruned model...\")\n# pruned_bleu = evaluate_bleu(pruned_model, test_sentences_en, test_references_de)\n# print(f\"Class-blind pruned model BLEU score: {pruned_bleu:.2f}\")\n\n# # Evaluate class-uniform pruned model\n# print(\"\\nEvaluating class-uniform pruned model...\")\n# pruned_blind_bleu = evaluate_bleu(pruned_model_blind, test_sentences_en, test_references_de)\n# print(f\"Class-uniform pruned model BLEU score: {pruned_blind_bleu:.2f}\")\n\n# # Evaluate class-distribution pruned model\n# print(\"\\nEvaluating class-distribution pruned model...\")\n# pruned_distribution_bleu = evaluate_bleu(pruned_model_distribution, test_sentences_en, test_references_de)\n# print(f\"Class-distribution pruned model BLEU score: {pruned_distribution_bleu:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:30:06.819835Z","iopub.execute_input":"2025-04-07T18:30:06.820071Z","iopub.status.idle":"2025-04-07T18:30:11.681265Z","shell.execute_reply.started":"2025-04-07T18:30:06.820051Z","shell.execute_reply":"2025-04-07T18:30:11.680155Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"sparsity_levels = [round(x * 0.1, 1) for x in range(1, 10)]  # 0.1 to 0.9\n# sparsity_levels = [0.2]\nprint(sparsity_levels)\nbleu_results = []\n\nwith open(\"bleu_scores.txt\", \"w\") as f:\n    for sparsity in sparsity_levels:\n        print(f\"\\nEvaluating at sparsity level: {sparsity}\")\n        f.write(f\"Sparsity Level: {sparsity}\\n\")\n\n        # You need to define how these pruned models are generated at each sparsity level\n        # Assuming you have a function like: prune_model(model, strategy, sparsity)\n\n        # Example placeholders\n        model = en2de\n        mask_dict = class_blind_pruning(param_dict,sparsity)\n        pruned_model = apply_masks_to_model(model, mask_dict)\n      \n        bleu_cb = evaluate_bleu(pruned_model, test_sentences_en, test_references_fr)\n\n        result_line = (\n            f\"Class-Blind: {bleu_cb:.2f}, \"\n        )\n\n        print(result_line)\n        f.write(result_line)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:43:38.121973Z","iopub.execute_input":"2025-04-07T18:43:38.122334Z","iopub.status.idle":"2025-04-07T20:07:59.586635Z","shell.execute_reply.started":"2025-04-07T18:43:38.122309Z","shell.execute_reply":"2025-04-07T20:07:59.585231Z"}},"outputs":[{"name":"stdout","text":"[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n\nEvaluating at sparsity level: 0.1\nClass-Blind: 0.18, \n\nEvaluating at sparsity level: 0.2\nClass-Blind: 0.18, \n\nEvaluating at sparsity level: 0.3\nClass-Blind: 0.18, \n\nEvaluating at sparsity level: 0.4\nClass-Blind: 0.21, \n\nEvaluating at sparsity level: 0.5\nClass-Blind: 0.23, \n\nEvaluating at sparsity level: 0.6\nClass-Blind: 0.00, \n\nEvaluating at sparsity level: 0.7\nClass-Blind: 0.00, \n\nEvaluating at sparsity level: 0.8\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-d3311352abb3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpruned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_masks_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbleu_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_references_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         result_line = (\n","\u001b[0;32m<ipython-input-16-f2fc0157b56e>\u001b[0m in \u001b[0;36mevaluate_bleu\u001b[0;34m(model, source_sentences, reference_sentences, batch_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbatch_translations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtranslations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_translations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, sentences, beam, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     ) -> List[str]:\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     def sample(\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/hub_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sentences, beam, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mtokenized_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mbatched_hypos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhypos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_hypos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokenized_sentences, beam, verbose, skip_invalid_size_inputs, inference_step_args, prefix_allowed_tokens_fn, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_invalid_size_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             translations = self.task.inference_step(\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minference_step_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/tasks/fairseq_task.py\u001b[0m in \u001b[0;36minference_step\u001b[0;34m(self, generator, models, sample, prefix_tokens, constraints)\u001b[0m\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             return generator.generate(\n\u001b[0m\u001b[1;32m    558\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, models, sample, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     def _generate(\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, sample, prefix_tokens, constraints, bos_token)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;34m\"EnsembleModel: forward_decoder\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             ):\n\u001b[0;32m--> 360\u001b[0;31m                 lprobs, avg_attn_scores = self.model.forward_decoder(\n\u001b[0m\u001b[1;32m    361\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mencoder_outs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36mforward_decoder\u001b[0;34m(self, tokens, encoder_outs, incremental_states, temperature)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# decode each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_incremental_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 decoder_out = model.decoder.forward(\n\u001b[0m\u001b[1;32m    826\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mencoder_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/transformer/transformer_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prev_output_tokens, encoder_out, incremental_state, features_only, full_context_alignment, alignment_layer, alignment_heads, src_lengths, return_all_hiddens)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         x, extra = self.extract_features(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0mprev_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mencoder_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/transformer/transformer_decoder.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, prev_output_tokens, encoder_out, incremental_state, full_context_alignment, alignment_layer, alignment_heads)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0malignment_heads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[0;32m--> 239\u001b[0;31m         return self.extract_features_scriptable(\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mprev_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/transformer/transformer_decoder.py\u001b[0m in \u001b[0;36mextract_features_scriptable\u001b[0;34m(self, prev_output_tokens, encoder_out, incremental_state, full_context_alignment, alignment_layer, alignment_heads)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mself_attn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             x, layer_attn, _ = layer(\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/modules/transformer_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_out, encoder_padding_mask, incremental_state, prev_self_attn_state, prev_attn_state, self_attn_mask, self_attn_padding_mask, need_attn, need_head_weights)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_input_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincremental_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             x, attn = self.encoder_attn(\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/modules/multihead_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, incremental_state, need_weights, static_kv, attn_mask, before_softmax, need_head_weights)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_decoder_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m# encoder-decoder attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}